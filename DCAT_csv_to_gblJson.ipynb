{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV to GeoBlacklight JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This script takes an input CSV of metadata and converts it to a GeoBlacklight JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a dictionary to translate single-value fields into GBLJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_dict = {\n",
    "    \"identifier\":[\"layer_slug_s\",\"dc_identifier_s\"],\n",
    "    \"title\":[\"dc_title_s\"],\n",
    "    \"description\":[\"dc_description_s\"],\n",
    "    \"dateIssued\":[\"dct_issued_s\"],\n",
    "    \"type\":[\"dc_type_s\"],\n",
    "    \"format\":[\"dc_format_s\"],\n",
    "    \"geometryType\":[\"layer_geom_type_s\"],\n",
    "    \"code\":[\"b1g_code_s\"],\n",
    "    \"solrYear\":[\"solr_year_i\"],\n",
    "    \"provenance\":[\"dct_provenance_s\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And this is a dictionary to translate multivalue fields into GBLJson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_dict = {\n",
    "    \"subject\":[\"dc_subject_sm\"],\n",
    "    \"keyword\":[\"b1g_keyword_sm\"],\n",
    "    \"temporalCoverage\":[\"dct_temporal_sm\"],\n",
    "    \"spatialCoverage\":[\"dct_spatial_sm\"],\n",
    "    \"publisher\":[\"dc_publisher_sm\"],\n",
    "    \"creator\":[\"dc_creator_sm\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This statement will create a folder to store the jsons if one does not already exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"json\"):\n",
    "    os.mkdir(\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the CSV with the GBL data. Change the string inside the open statement to match your file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csvfile = open('hennepin-DCAT.csv', 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reads the CSV into a dictionary and sets the date modified to now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = csv.DictReader(csvfile)\n",
    "date_modified = datetime.today().strftime('%Y-%m-%d')+\"T\"+datetime.today().strftime('%X')+\"Z\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The script creates a Python dictionary and adds values from the CSV.\n",
    "\n",
    "1. A dictionary is created first with default values that are the same for all records\n",
    "\n",
    "\n",
    "2. Each row is examined for an identifying code. This code separates the records into collections. A folder for each code is created in the json folder so that the jsons can be sorted into their respective collection.\n",
    "\n",
    "\n",
    "3. The script then goes through the single and multiple dictionaries that were defined above and writes them into the starting dictionary.\n",
    "\n",
    "### Certain fields  need to be reordered or combined before being added to the dictionary\n",
    "\n",
    "4. Next, the script looks for the the Bounding Box field and splits the W,S,E,N values into their own variables. These are reordered as W,E,N,S and put inside an well-known text format using ENVELOPE().\n",
    "\n",
    "\n",
    "5. The references field needs to be created, so the script looks for relevant fields, writes them to a list if they have a value, and then formats and adds the list to the small dictionary before writing the json file.\n",
    "\n",
    "\n",
    "6. Finally, the unique identifier is pulled out, the output filename is named according to that unique identifier, and the output json file is written. This happens for every row in the CSV, so each record will be written to its own JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in reader:\n",
    "    code = \"\"\n",
    "    ref = []\n",
    "    \n",
    "#starting dictionary with default values\n",
    "    small_dict = {\"geoblacklight_version\":\"1.0\",\"dc_rights_s\":\"Public\",\"layer_modified_dt\":date_modified}\n",
    "    for key,val in row.items():\n",
    "        #Creates a new folder for each unique Code\n",
    "        if key == \"code\":\n",
    "            code = val\n",
    "            if not os.path.exists(\"json/\" + val):\n",
    "                os.mkdir(\"json/\" + val)\n",
    "        \n",
    "#Looks just for the single valued fields and creates a dictionary of them\n",
    "        if key in single_dict:\n",
    "            for fieldname in single_dict[key]:\n",
    "                small_dict[fieldname] = val\n",
    "        \n",
    "#Looks for the multivalued fields (split with a pipe '|') and creates a dictionary of them.\n",
    "        if key in multiple_dict:\n",
    "            for fieldname in multiple_dict[key]:\n",
    "                small_dict[fieldname] = val.split('|')\n",
    "                \n",
    "# Looks for bounding box, splits the values and re-orders them.\n",
    "        if key == \"spatial\":\n",
    "            val = val.split(',')\n",
    "            if len(val) == 4: #takes care of bounding box values and calculates centroid\n",
    "                west = val[0]\n",
    "                south = val[1]\n",
    "                east = val[2]\n",
    "                north = val[3]\n",
    "                small_dict[\"solr_geom\"] = \"ENVELOPE(\"+west+\",\"+east+\",\"+north+\",\"+south+\")\"\n",
    "            else: #if the bounding box doesn't have all coordinates, just write values as null\n",
    "                small_dict[\"solr_geom\"] = \"NULL\"\n",
    "        if key == \"landingPage\" and val != '':\n",
    "            to_append = '\"http://schema.org/url\":\"' + val + '\"'\n",
    "            #print(to_append)\n",
    "            ref.append(to_append)\n",
    "        if key == \"downloadURL\" and val != '':\n",
    "            to_append = '\"http://schema.org/downloadUrl\":\"' + val + '\"'\n",
    "            ref.append(to_append)\n",
    "        if key == \"mapServer\" and val != '':\n",
    "            to_append = '\"urn:x-esri:serviceType:ArcGIS#DynamicMapLayer\":\"' + val + '\"'\n",
    "            ref.append(to_append)\n",
    "        if key == \"featureServer\" and val != '':\n",
    "            to_append = '\"urn:x-esri:serviceType:ArcGIS#FeatureLayer\":\"' + val + '\"'\n",
    "            ref.append(to_append)\n",
    "        if key == \"imageServer\" and val != '':\n",
    "            to_append = '\"urn:x-esri:serviceType:ArcGIS#ImageMapLayer\":\"' + val + '\"'\n",
    "            ref.append(to_append)\n",
    "    small_dict[\"dct_references_s\"] = '{' + (','.join(ref)) + '}'\n",
    "    iden = row['identifier']\n",
    "    filename = iden + \".json\"\n",
    "    \n",
    "    \n",
    "#writes to a json with the identifier as the filename \n",
    "    with open(\"json/\"+code+\"/\"+filename, 'w') as jsonfile: \n",
    "        json.dump(small_dict,jsonfile,indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Script authored by Emily Ruetz @ruetz007; Updated by Karen Majewicz @karenmajewicz*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
